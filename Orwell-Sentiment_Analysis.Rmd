```{r}
library(tidytext) # text mining using tidy tools
library(textdata) # get sentiment lexicons
library(tidyverse)
library(scales)
library(igraph) # Graphing Bigrams
library(ggraph) # Graphing Bigrams
```

```{r}
# import raw data 
animal_farm <- read_lines(
  file = "http://gutenberg.net.au/ebooks01/0100011.txt",
  skip_empty_rows = TRUE,
  skip = 37, # remove metadata about book
  n_max = 2500) # remove appendix

nineteen_84 <- read_lines(
  file = "http://gutenberg.net.au/ebooks01/0100021.txt",
  skip_empty_rows = TRUE,
  skip = 38, # remove metadata about book
  n_max = 8344) # remove appendix

air <- read_lines(
  file = "http://gutenberg.net.au/ebooks02/0200031.txt",
  skip_empty_rows = TRUE,
  skip = 44, # remove metadata about book
  n_max = 8340) # remove appendix

homage <- read_lines(
  file = "http://gutenberg.net.au/ebooks02/0201111.txt",
  skip_empty_rows = TRUE,
  skip = 40, # remove metadata about book
  n_max = 8000) # remove appendix

daughter <- read_lines(
  file = "http://gutenberg.net.au/ebooks02/0200011.txt",
  skip_empty_rows = TRUE,
  skip = 39, # remove metadata about book
  n_max = 10000) # remove appendix
```

```{r}
# Load stop words: words that are not useful for an analysis, typically extremely common words such as “the”, “of”, “to”, and so forth in English
data(stop_words)

# Load all the books and then separate into each individual word
animal_df <- tibble(text = animal_farm) %>%
  mutate(chapter = cumsum(str_detect(text, regex("^chapter [I-X]", ignore_case = TRUE)))) %>%
  filter(!str_detect(text, regex("^chapter [I-X]", ignore_case = TRUE))) %>%
  rownames_to_column(var = "line") %>%
  mutate(line = as.integer(line)) %>%
  mutate(index = line %/% 50)

animal_df

animal_tidy_df <- animal_df %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words)

animal_tidy_df

daughter_df <- tibble(text = daughter) %>%
  mutate(chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]", ignore_case = TRUE)))) %>%
  filter(!str_detect(text, regex("^chapter [\\divxlc]", ignore_case = TRUE))) %>%
  rownames_to_column(var = "line") %>%
  mutate(line = as.integer(line)) %>%
  mutate(index = line %/% 50)

daughter_tidy_df <- daughter_df %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words)

nine_df <- tibble(text = nineteen_84) %>%
  mutate(chapter = cumsum(str_detect(text, regex("^chapter [1-9]", ignore_case = TRUE)))) %>%
  filter(!str_detect(text, regex("^chapter [1-9]", ignore_case = TRUE))) %>%
  rownames_to_column(var = "line") %>%
  mutate(line = as.integer(line)) %>%
  mutate(index = line %/% 50)

nine_tidy_df <- nine_df %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words)

air_df <- tibble(text = air) %>%
  mutate(chapter = cumsum(str_detect(text, regex("^PART [IVXLCDM]", ignore_case = TRUE)))) %>%
  filter(!str_detect(text, regex("^PART [IVXLCDM]", ignore_case = TRUE))) %>%
  rownames_to_column(var = "line") %>%
  mutate(line = as.integer(line)) %>%
  mutate(index = line %/% 50)

air_tidy_df <- air_df %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words)

homage_df <- tibble(text = homage) %>%
  mutate(chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]", ignore_case = TRUE)))) %>%
  filter(!str_detect(text, regex("^chapter [\\divxlc]", ignore_case = TRUE))) %>%
  rownames_to_column(var = "line") %>%
  mutate(line = as.integer(line)) %>%
  mutate(index = line %/% 50)

homage_tidy_df <- homage_df %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words)

# combine all the books
sum_df_raw <- bind_rows(mutate(animal_df, Title = "Animal Farm"),
                    mutate(daughter_df, Title = "A Clergyman's Daughter"),
                    mutate(nine_df, Title = "Nineteen Eighty-Four"),
                    mutate(air_df, Title = "Coming up for Air"),
                    mutate(homage_df, Title = "Homage to Catalonia")
)
sum_df_raw

sum_df <- bind_rows(mutate(animal_tidy_df, Title = "Animal Farm"),
                    mutate(daughter_tidy_df, Title = "A Clergyman's Daughter"),
                    mutate(nine_tidy_df, Title = "Nineteen Eighty-Four"),
                    mutate(air_tidy_df, Title = "Coming up for Air"),
                    mutate(homage_tidy_df, Title = "Homage to Catalonia")
)
sum_df

# load sentiment lexicons
tns <- getNamespace("textdata")
assignInNamespace(x = "printer", value = function(...) 1, ns = tns)
                  
bing <- tidytext::get_sentiments("bing") 
afinn <- tidytext::get_sentiments("afinn")
nrc <- tidytext::get_sentiments("nrc") 

# sentiment lexicons limitations
text_pos <- "This is my favorite book. I like it."
text_neg <- "This is not my favorite book. I don't like it."

df_limitations <- tibble(
  text = c(text_pos, text_neg),
  examples = c("text_pos", "text_neg")
)

df_limitations %>%
  unnest_tokens(word, text) %>%
  inner_join(afinn, by = "word") %>%
  inner_join(bing, by = "word")


# Data Frame used for conducting correlation study 
raw_frequency_plot <- sum_df %>% 
  mutate(word = str_extract(word, "[a-z']+")) %>%
  count(Title, word) %>%
  group_by(Title) %>%
  mutate(Proportion = n / sum(n)) %>% 
  select(-n)

raw_frequency_plot

```

```{r}
sum_df %>% filter(Title == "Animal Farm") %>%
        inner_join(bing, by = "word") %>%
        count(word, sentiment, sort = TRUE) %>%
        group_by(sentiment) %>%
        slice_head(n=10) %>% 
        ungroup() %>%
        mutate(word = reorder(word, n)) %>%
        ggplot(aes(n, word, fill = sentiment)) +
        geom_col(show.legend = FALSE) +
        facet_wrap(~sentiment, scales = "free_y") +
        theme_light() +
        labs(title = "Negative/Positive Words in Orwell's Animal Farm",
             subtitle = "Top 10 words, BING lexicon",
             x = "Number of words",
             y = NULL)
```


```{r}
sum_df %>% filter(Title == "Animal Farm") %>%
        inner_join(nrc, by = "word") %>%
        count(word, sentiment, sort = TRUE) %>%
        filter(!word %in% c("words", "feeling")) %>% #remove tokens
        group_by(sentiment) %>%
        slice_head(n=5) %>% 
        ungroup() %>%
        mutate(word = reorder(word, n)) %>%
        ggplot(aes(n, word, fill = sentiment)) +
        geom_col(show.legend = FALSE) +
        facet_wrap(~sentiment, scales = "free_y") +
        theme_light() +
        labs(title = "Emotional Words in Orwell's Animal Farm",
             subtitle = "Top 5 words, NRC lexicon",
             x = NULL, y = NULL,
             caption = "")
```

```{r}
sum_df %>% filter(Title == "Animal Farm") %>%
        inner_join(afinn, by = "word") %>%
        group_by(chapter) %>%
        summarise(sentiment = sum(value)) %>%
        ungroup() %>%
        mutate(positive = sentiment > 0,
               chapter = as.factor(chapter)) %>%
        ggplot(aes(chapter, sentiment)) +
        geom_col(aes(fill = positive), show.legend = FALSE) +
        theme_minimal() +
        theme(panel.grid.major.x = element_blank()) +
        labs(title = "Sentiment analysis of Orwell's Animal Farm",
             subtitle = "Score by chapter, afinn lexicon",
             caption = "")
```

```{r}
frequency_plot2 <- raw_frequency_plot %>% 
        pivot_wider(names_from = Title, values_from = Proportion) %>%
        pivot_longer(`A Clergyman's Daughter`,
                     names_to = "Title", values_to = "Proportion")
      
      ggplot(frequency_plot2, aes(x = Proportion, y = `Animal Farm`, 
                                  color = abs(`Animal Farm` - Proportion))) +
        geom_abline(color = "gray40", lty = 2) +
        geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
        geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
        scale_x_log10(labels = percent_format()) +
        scale_y_log10(labels = percent_format()) +
        scale_color_gradient(limits = c(0, 0.001), 
                             low = "darkslategray4", high = "gray75") +
        facet_wrap(~Title, ncol = 1) +
        theme(legend.position="none") +
        labs(y = "Animal Farm", x = NULL)
```

```{r}
frequency_plot2.1 <- raw_frequency_plot %>% 
      pivot_wider(names_from = Title, values_from = Proportion) %>%
      pivot_longer(`Nineteen Eighty-Four`,
                   names_to = "Title", values_to = "Proportion")
    
    ggplot(frequency_plot2.1, aes(x = Proportion, y = `Animal Farm`, 
                                  color = abs(`Animal Farm` - Proportion))) +
      geom_abline(color = "gray40", lty = 2) +
      geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
      geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
      scale_x_log10(labels = percent_format()) +
      scale_y_log10(labels = percent_format()) +
      scale_color_gradient(limits = c(0, 0.001), 
                           low = "darkslategray4", high = "gray75") +
      facet_wrap(~Title, ncol = 1) +
      theme(legend.position="none") +
      labs(y = "Animal Farm", x = NULL)
```

```{r}
 frequency_plot3.1 <- raw_frequency_plot %>% 
        pivot_wider(names_from = Title, values_from = Proportion) %>%
        pivot_longer(`Coming up for Air`,
                     names_to = "Title", values_to = "Proportion")
      
      ggplot(frequency_plot3.1, aes(x = Proportion, y = `Animal Farm`, 
                                    color = abs(`Animal Farm` - Proportion))) +
        geom_abline(color = "gray40", lty = 2) +
        geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
        geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
        scale_x_log10(labels = percent_format()) +
        scale_y_log10(labels = percent_format()) +
        scale_color_gradient(limits = c(0, 0.001), 
                             low = "darkslategray4", high = "gray75") +
        facet_wrap(~Title, ncol = 1) +
        theme(legend.position="none") +
        labs(y = "Animal Farm", x = NULL)
```

```{r}
frequency_plot4.1 <- raw_frequency_plot %>% 
        pivot_wider(names_from = Title, values_from = Proportion) %>%
        pivot_longer(`Homage to Catalonia`,
                     names_to = "Title", values_to = "Proportion")
      
      ggplot(frequency_plot4.1, aes(x = Proportion, y = `Animal Farm`, 
                                    color = abs(`Animal Farm` - Proportion))) +
        geom_abline(color = "gray40", lty = 2) +
        geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
        geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
        scale_x_log10(labels = percent_format()) +
        scale_y_log10(labels = percent_format()) +
        scale_color_gradient(limits = c(0, 0.001), 
                             low = "darkslategray4", high = "gray75") +
        facet_wrap(~Title, ncol = 1) +
        theme(legend.position="none") +
        labs(y = "Animal Farm", x = NULL)
```

```{r}
freq1 <- raw_frequency_plot %>% 
        pivot_wider(names_from = Title, values_from = Proportion) %>%
        pivot_longer(`Animal Farm`,
                     names_to = "Title", values_to = "Proportion")
      
      cor_test_1984 <- cor.test(data = freq1[freq1$Title == "Animal Farm",],
                                ~ Proportion + `Nineteen Eighty-Four`)
      cor_test_catalonia <- cor.test(data = freq1[freq1$Title == "Animal Farm",],
                                     ~ Proportion + `Homage to Catalonia`)
      cor_test_air <- cor.test(data = freq1[freq1$Title == "Animal Farm",],
                               ~ Proportion + `Coming up for Air`)
      cor_test_daughter <- cor.test(data = freq1[freq1$Title == "Animal Farm",],
                                    ~ Proportion + `A Clergyman's Daughter`)
      
      results <- list(
        "Correlation with Nineteen Eighty-Four" = cor_test_1984,
        "Correlation with Homage to Catalonia" = cor_test_catalonia,
        "Correlation with Coming up for Air" = cor_test_air,
        "Correlation with A Clergyman's Daughter" = cor_test_daughter
      )
      results
```

```{r}
df_bigrams <- sum_df_raw %>% filter(Title == "Animal Farm") %>%
          unnest_tokens(bigram, text, token = 'ngrams', n = 2) %>% filter(!is.na(bigram))
        
        bigrams_separated <- df_bigrams %>%
          separate(bigram, c("word1", "word2"), sep = " ")
        
        bigrams_filtered <- bigrams_separated %>%
          filter(!word1 %in% stop_words$word) %>%
          filter(!word2 %in% stop_words$word)
        
        # new bigram counts:
        bigram_counts <- bigrams_filtered %>% 
          count(word1, word2, sort = TRUE)
        
        bigram_graph <- bigram_counts %>%
          filter(n > 5) %>%
          graph_from_data_frame()
        
        set.seed(2020)
        
        a <- grid::arrow(type = "closed", length = unit(.15, "inches"))
        
        ggraph(bigram_graph, layout = "fr") +
          geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
                         arrow = a, end_cap = circle(.07, 'inches')) +
          geom_node_point(color = "lightblue", size = 5) +
          geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
          theme_void()
```

```{r}
df_trigrams <- sum_df_raw %>% filter(Title == "Animal Farm") %>%
        unnest_tokens(trigram, text, token = "ngrams", n = 3) %>%
        filter(!is.na(trigram)) %>%
        separate(trigram, c("word1", "word2", "word3"), sep = " ") %>%
        filter(!word1 %in% stop_words$word,
               !word2 %in% stop_words$word,
               !word3 %in% stop_words$word) %>%
        count(word1, word2, word3, sort = TRUE)
      
      trigram_graph <- df_trigrams %>%
        filter(n > 1) %>%
        graph_from_data_frame()
      
      set.seed(2021)
      
      a <- grid::arrow(type = "closed", length = unit(.15, "inches"))
      
      ggraph(trigram_graph, layout = "fr") +
        geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
                       arrow = a, end_cap = circle(.07, 'inches')) +
        geom_node_point(color = "lightgreen", size = 5) +
        geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
        theme_void()
```

